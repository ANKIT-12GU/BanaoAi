{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e9e11e-c1b0-4249-9f9b-2146330e6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cf02db7-4e57-46a2-afd4-d018d5bb6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files to process\n",
    "csv_files = [\n",
    "    'dataset/gossipcop_fake.csv',\n",
    "    'dataset/gossipcop_real.csv',\n",
    "    'dataset/politifact_fake.csv',\n",
    "    'dataset/politifact_real.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6808be6-42ba-40a4-bf1b-a5f926d501da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated CSV\n",
    "def save_updated_csv(data, original_filename, step, step_name):\n",
    "    base_name = os.path.basename(original_filename)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    new_filename = f\"{name}_{step}_{step_name}_updated{ext}\"\n",
    "    output_path = os.path.join('output', new_filename)\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Updated CSV after step {step} ({step_name}) saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc0bf12a-a8e6-4b72-bd1a-f9310c5d7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text\n",
    "def preprocess_text(data, filename):\n",
    "    print(\"Step 1: Preprocessing text...\")\n",
    "    import re\n",
    "    data['cleaned_text'] = data['title'].apply(lambda text: re.sub(r'[^a-zA-Z0-9 ]', '', re.sub(r'<.*?>', '', text.lower())))\n",
    "    save_updated_csv(data, filename, 'step1', 'preprocessing')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe30c12f-1011-42d7-b767-9ab87ee57dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Named Entities\n",
    "def extract_entities(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    entity_counts = {'ORG': 0, 'GPE': 0, 'PERSON': 0}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in entity_counts:\n",
    "            entity_counts[ent.label_] += 1\n",
    "    return entity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b6e75c-0210-4c83-8913-b13824629893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, filename):\n",
    "    print(\"Step 2: Extracting Named Entities...\")\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    entity_features = data['cleaned_text'].apply(lambda x: extract_entities(x, nlp))\n",
    "    data['org_count'] = entity_features.apply(lambda x: x['ORG'])\n",
    "    data['gpe_count'] = entity_features.apply(lambda x: x['GPE'])\n",
    "    data['person_count'] = entity_features.apply(lambda x: x['PERSON'])\n",
    "    save_updated_csv(data, filename, 'step2', 'entity_extraction')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "190f0635-4fe2-44ee-990e-d65c340a37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sentiment\n",
    "def calculate_features(data, filename):\n",
    "    print(\"Step 3: Calculating sentiment and article length...\")\n",
    "    data['sentiment'] = data['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    data['article_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))\n",
    "    save_updated_csv(data, filename, 'step3', 'feature_calculation')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d247fd5f-23c6-4d9e-aa07-2010119844df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive Modeling\n",
    "def predictive_modeling(data, filename):\n",
    "    print(\"Step 4: Predictive Modeling...\")\n",
    "    features = ['org_count', 'gpe_count', 'person_count', 'sentiment', 'article_length']\n",
    "    X = data[features]\n",
    "    y = data['engagement']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Random Forest Regressor\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and Evaluation\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "    # For classification-like metrics, binarize predictions and actuals for evaluation\n",
    "    y_test_binarized = np.where(y_test > np.median(y_test), 1, 0)\n",
    "    predictions_binarized = np.where(predictions > np.median(predictions), 1, 0)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_binarized, predictions_binarized)\n",
    "    f1 = f1_score(y_test_binarized, predictions_binarized)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "\n",
    "    # Save model results\n",
    "    data['predicted_engagement'] = model.predict(X)\n",
    "    save_updated_csv(data, filename, 'step4', 'modeling')\n",
    "\n",
    "    return model, mae, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ef5ae1f-c67f-413f-be94-e408971f934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def create_visualizations(data, filename):\n",
    "    print(\"Step 5: Creating visualizations...\")\n",
    "    os.makedirs('visualizations', exist_ok=True)\n",
    "\n",
    "    # Entity Frequency Bar Chart\n",
    "    entity_counts = data[['org_count', 'gpe_count', 'person_count']].sum()\n",
    "    entity_counts.plot(kind='bar', color=['blue', 'green', 'red'])\n",
    "    plt.title('Entity Frequency')\n",
    "    plt.xlabel('Entity Type')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig(f'visualizations/{os.path.basename(filename)}_entity_frequency.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Scatter Plot: Sentiment vs Engagement\n",
    "    sns.scatterplot(x='sentiment', y='engagement', data=data)\n",
    "    plt.title('Sentiment vs Engagement')\n",
    "    plt.xlabel('Sentiment Polarity')\n",
    "    plt.ylabel('Engagement')\n",
    "    plt.savefig(f'visualizations/{os.path.basename(filename)}_sentiment_engagement.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Heatmap: Feature Correlation\n",
    "    numeric_data = data.select_dtypes(include=['number'])  # Select only numeric columns\n",
    "    correlation_matrix = numeric_data.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Feature Correlation')\n",
    "    plt.savefig(f'visualizations/{os.path.basename(filename)}_feature_correlation.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fab16439-12d2-494a-a38c-584377de8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline\n",
    "def main():\n",
    "    for file in csv_files:\n",
    "        print(f\"Processing file: {file}\")\n",
    "        data = pd.read_csv(file)\n",
    "\n",
    "        # Step 1: Preprocessing\n",
    "        data = preprocess_text(data, file)\n",
    "\n",
    "        # Step 2: Named Entity Recognition and Feature Extraction\n",
    "        data = extract_features(data, file)\n",
    "\n",
    "        # Step 3: Calculate Sentiment and Additional Features\n",
    "        data = calculate_features(data, file)\n",
    "\n",
    "        # Step 4: Placeholder Engagement Metric\n",
    "        print(\"Step 4: Creating placeholder engagement metric...\")\n",
    "        data['engagement'] = data['org_count'] + data['gpe_count'] + data['person_count'] + data['sentiment'] * 10\n",
    "\n",
    "        # Step 5: Predictive Modeling\n",
    "        model, mae, accuracy, f1 = predictive_modeling(data, file)\n",
    "        print(f\"Results for {file}: MAE={mae}, Accuracy={accuracy}, F1-Score={f1}\")\n",
    "\n",
    "        # Step 6: Visualization\n",
    "        create_visualizations(data, file)\n",
    "\n",
    "    print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709fb2e8-e2aa-42e2-8e68-7bd54106a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: dataset/gossipcop_fake.csv\n",
      "Step 1: Preprocessing text...\n",
      "Updated CSV after step step1 (preprocessing) saved as output\\gossipcop_fake_step1_preprocessing_updated.csv\n",
      "Step 2: Extracting Named Entities...\n",
      "Updated CSV after step step2 (entity_extraction) saved as output\\gossipcop_fake_step2_entity_extraction_updated.csv\n",
      "Step 3: Calculating sentiment and article length...\n",
      "Updated CSV after step step3 (feature_calculation) saved as output\\gossipcop_fake_step3_feature_calculation_updated.csv\n",
      "Step 4: Creating placeholder engagement metric...\n",
      "Step 4: Predictive Modeling...\n",
      "Mean Absolute Error: 0.035913856559455226\n",
      "Accuracy: 0.9990610328638497\n",
      "F1-Score: 0.9989417989417989\n",
      "Updated CSV after step step4 (modeling) saved as output\\gossipcop_fake_step4_modeling_updated.csv\n",
      "Results for dataset/gossipcop_fake.csv: MAE=0.035913856559455226, Accuracy=0.9990610328638497, F1-Score=0.9989417989417989\n",
      "Step 5: Creating visualizations...\n",
      "Processing file: dataset/gossipcop_real.csv\n",
      "Step 1: Preprocessing text...\n",
      "Updated CSV after step step1 (preprocessing) saved as output\\gossipcop_real_step1_preprocessing_updated.csv\n",
      "Step 2: Extracting Named Entities...\n",
      "Updated CSV after step step2 (entity_extraction) saved as output\\gossipcop_real_step2_entity_extraction_updated.csv\n",
      "Step 3: Calculating sentiment and article length...\n",
      "Updated CSV after step step3 (feature_calculation) saved as output\\gossipcop_real_step3_feature_calculation_updated.csv\n",
      "Step 4: Creating placeholder engagement metric...\n",
      "Step 4: Predictive Modeling...\n",
      "Mean Absolute Error: 0.012640247611858942\n",
      "Accuracy: 0.998513674197384\n",
      "F1-Score: 0.9983405243942914\n",
      "Updated CSV after step step4 (modeling) saved as output\\gossipcop_real_step4_modeling_updated.csv\n",
      "Results for dataset/gossipcop_real.csv: MAE=0.012640247611858942, Accuracy=0.998513674197384, F1-Score=0.9983405243942914\n",
      "Step 5: Creating visualizations...\n",
      "Processing file: dataset/politifact_fake.csv\n",
      "Step 1: Preprocessing text...\n",
      "Updated CSV after step step1 (preprocessing) saved as output\\politifact_fake_step1_preprocessing_updated.csv\n",
      "Step 2: Extracting Named Entities...\n",
      "Updated CSV after step step2 (entity_extraction) saved as output\\politifact_fake_step2_entity_extraction_updated.csv\n",
      "Step 3: Calculating sentiment and article length...\n",
      "Updated CSV after step step3 (feature_calculation) saved as output\\politifact_fake_step3_feature_calculation_updated.csv\n",
      "Step 4: Creating placeholder engagement metric...\n",
      "Step 4: Predictive Modeling...\n",
      "Mean Absolute Error: 0.1187470849712229\n",
      "Accuracy: 0.9885057471264368\n",
      "F1-Score: 0.9795918367346939\n",
      "Updated CSV after step step4 (modeling) saved as output\\politifact_fake_step4_modeling_updated.csv\n",
      "Results for dataset/politifact_fake.csv: MAE=0.1187470849712229, Accuracy=0.9885057471264368, F1-Score=0.9795918367346939\n",
      "Step 5: Creating visualizations...\n",
      "Processing file: dataset/politifact_real.csv\n",
      "Step 1: Preprocessing text...\n",
      "Updated CSV after step step1 (preprocessing) saved as output\\politifact_real_step1_preprocessing_updated.csv\n",
      "Step 2: Extracting Named Entities...\n",
      "Updated CSV after step step2 (entity_extraction) saved as output\\politifact_real_step2_entity_extraction_updated.csv\n",
      "Step 3: Calculating sentiment and article length...\n",
      "Updated CSV after step step3 (feature_calculation) saved as output\\politifact_real_step3_feature_calculation_updated.csv\n",
      "Step 4: Creating placeholder engagement metric...\n",
      "Step 4: Predictive Modeling...\n",
      "Mean Absolute Error: 0.12234412620712617\n",
      "Accuracy: 0.992\n",
      "F1-Score: 0.9866666666666667\n",
      "Updated CSV after step step4 (modeling) saved as output\\politifact_real_step4_modeling_updated.csv\n",
      "Results for dataset/politifact_real.csv: MAE=0.12234412620712617, Accuracy=0.992, F1-Score=0.9866666666666667\n",
      "Step 5: Creating visualizations...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e67dc-d658-4e35-ae0a-878500235d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
